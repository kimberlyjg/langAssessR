---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# langAssessR

<!-- badges: start -->
[![R-CMD-check](https://github.com/kimberlyjg/langAssessR/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/kimberlyjg/langAssessR/actions/workflows/R-CMD-check.yaml)
<!-- badges: end -->

R package for bias-aware, explainable, and generalizable language-based assessment with built-in contamination testing, cross-context validation, and fairness auditing.

## Installation

You can install the development version of langAssessR from GitHub:

```{r install, eval=FALSE}
# install.packages("devtools")
devtools::install_github("kimberlyjg/langAssessR")
```

## Example

This is a basic example showing the core functionality:

```{r example}
library(langAssessR)

# Simulate data
sim <- simulate_lang_data(n = 200, n_sites = 3)

# Extract features from transcripts
features <- la_features(sim$transcripts$narrative)
head(features)

# Fit a model
model <- la_fit(features[,-1], sim$participants$y_bin)

# Make predictions and evaluate
pred <- la_predict(model, features[,-1])
eval <- la_eval(pred, sim$participants$y_bin)
eval$summary

# Check cross-site generalization
cv <- cross_context_cv(features[,-1], sim$participants$y_bin, sim$participants$site)
cv$site_estimates
```

